

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Encoder-Decoder model for ENSO-forecasting &mdash; NinoLearn 0.1 documentation</title>
  

  
  
    <link rel="shortcut icon" href="../_static/logo.png"/>
  
  
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../_static/jquery.js"></script>
        <script type="text/javascript" src="../_static/underscore.js"></script>
        <script type="text/javascript" src="../_static/doctools.js"></script>
        <script type="text/javascript" src="../_static/language_data.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Some forecasts" href="../forecasts.html" />
    <link rel="prev" title="Deep ensemble for ENSO-forecasting" href="deep_ensemble.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> NinoLearn
          

          
            
            <img src="../_static/logo_small.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                0.1
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../intro.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../install.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../package.html">NinoLearn package</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../tutorials.html">Tutorials</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="download_and_read_raw_data.html">Download and read raw data</a></li>
<li class="toctree-l2"><a class="reference internal" href="prepare_data.html">Data preparation and read postprocessed data</a></li>
<li class="toctree-l2"><a class="reference internal" href="postprocess_data.html">Postprocess data</a></li>
<li class="toctree-l2"><a class="reference internal" href="deep_ensemble.html">Deep ensemble for ENSO-forecasting</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Encoder-Decoder model for ENSO-forecasting</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Read-data">Read data</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Generate-the-feature-and-label-arrays">Generate the feature and label arrays</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Split-the-data-set">Split the data set</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Fit-the-model">Fit the model</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Make-predictions-on-the-test-data-set">Make predictions on the test data set</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Plot-prediction-for-the-ONI">Plot prediction for the ONI</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Evaluate-the-seasonal-skill-for-predicting-the-ONI">Evaluate the seasonal skill for predicting the ONI</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Check-the-correlations-on-a-map">Check the correlations on a map</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Animate-the-full-test-prediction">Animate the full test prediction</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../forecasts.html">Some forecasts</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">NinoLearn</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../tutorials.html">Tutorials</a> &raquo;</li>
        
      <li>Encoder-Decoder model for ENSO-forecasting</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/jupyter_notebook_tutorials/encoder_decoder.ipynb.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput,
div.nbinput div.prompt,
div.nbinput div.input_area,
div.nbinput div[class*=highlight],
div.nbinput div[class*=highlight] pre,
div.nboutput,
div.nbinput div.prompt,
div.nbinput div.output_area,
div.nboutput div[class*=highlight],
div.nboutput div[class*=highlight] pre {
    background: none;
    border: none;
    padding: 0 0;
    margin: 0;
    box-shadow: none;
}

/* avoid gaps between output lines */
div.nboutput div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput,
div.nboutput {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput,
    div.nboutput {
        flex-direction: column;
    }
}

/* input container */
div.nbinput {
    padding-top: 5px;
}

/* last container */
div.nblast {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput div.prompt,
div.nboutput div.prompt {
    min-width: 5ex;
    padding-top: 0.4em;
    padding-right: 0.4em;
    text-align: right;
    flex: 0;
}
@media (max-width: 540px) {
    div.nbinput div.prompt,
    div.nboutput div.prompt {
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput div.prompt.empty {
        padding: 0;
    }
}

/* disable scrollbars on prompts */
div.nbinput div.prompt pre,
div.nboutput div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput div.input_area,
div.nboutput div.output_area {
    padding: 0.4em;
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput div.input_area,
    div.nboutput div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    background: #f5f5f5;
}

/* override MathJax center alignment in output cells */
div.nboutput div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput div.math p {
    text-align: left;
}

/* standard error */
div.nboutput div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast,
.nboutput.nblast {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast + .nbinput {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="Encoder-Decoder-model-for-ENSO-forecasting">
<h1>Encoder-Decoder model for ENSO-forecasting<a class="headerlink" href="#Encoder-Decoder-model-for-ENSO-forecasting" title="Permalink to this headline">¶</a></h1>
<p>The Encoder-Decoder model is enspired by the architecture of autoencoders. Here, the size of the input layer of the neural network is the same size as the output layer. Furthermore, there is a so-called bottleneck layer present in the network which has less neurons than the input/output layers. For an Autoencoder the label and feature are the same. Because of the bottleneck layer, the network is forced to learn a lower dimesional expression of the input</p>
<p>For the Encoder-Decoder model (DEM), a time lag between the feature and the label is introduced. Such that the DEM is a forecast model. Hence, the DEM is forced to learn a lower dimensional expression that explains best the future state of the considered variable field.</p>
<p>In this tutorial, the considered variable field is again the SST anomaly data from the ERSSTv5 data set.</p>
<div class="section" id="Read-data">
<h2>Read data<a class="headerlink" href="#Read-data" title="Permalink to this headline">¶</a></h2>
<p>In the following cell, we read the SST anoamly data that was computed in an earlier tutorial.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">ninolearn.IO.read_post</span> <span class="k">import</span> <span class="n">data_reader</span>

<span class="c1">#read data</span>
<span class="n">reader</span> <span class="o">=</span> <span class="n">data_reader</span><span class="p">(</span><span class="n">startdate</span><span class="o">=</span><span class="s1">&#39;1959-11&#39;</span><span class="p">,</span> <span class="n">enddate</span><span class="o">=</span><span class="s1">&#39;2018-12&#39;</span><span class="p">)</span>

<span class="c1"># read SST data and directly make seasonal averages</span>
<span class="n">SSTA</span> <span class="o">=</span> <span class="n">reader</span><span class="o">.</span><span class="n">read_netcdf</span><span class="p">(</span><span class="s1">&#39;sst&#39;</span><span class="p">,</span> <span class="n">dataset</span><span class="o">=</span><span class="s1">&#39;ERSSTv5&#39;</span><span class="p">,</span> <span class="n">processed</span><span class="o">=</span><span class="s1">&#39;anom&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">rolling</span><span class="p">(</span><span class="n">time</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()[</span><span class="mi">2</span><span class="p">:]</span>

<span class="c1"># read the ONI for later comparison</span>
<span class="n">oni</span> <span class="o">=</span> <span class="n">reader</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;oni&#39;</span><span class="p">)[</span><span class="mi">2</span><span class="p">:]</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/home/paul/miniconda2/envs/ninolearn/lib/python3.6/site-packages/xarray/core/nanops.py:160: RuntimeWarning: Mean of empty slice
  return np.nanmean(a, axis=axis, dtype=dtype)
</pre></div></div>
</div>
</div>
<div class="section" id="Generate-the-feature-and-label-arrays">
<h2>Generate the feature and label arrays<a class="headerlink" href="#Generate-the-feature-and-label-arrays" title="Permalink to this headline">¶</a></h2>
<p>The following cell generates the feature and label arrays. Because <code class="docutils literal notranslate"><span class="pre">feature</span></code> and <code class="docutils literal notranslate"><span class="pre">label</span></code> need to refer to an other object in the backend so that they can be changed without influencing each other.</p>
<p>Moreover, the data is scalled because this helps the DEM to be more precise.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="k">import</span> <span class="n">StandardScaler</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="c1"># make deep copies of the sst data</span>
<span class="n">feature</span> <span class="o">=</span> <span class="n">SSTA</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">deep</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">label</span> <span class="o">=</span> <span class="n">SSTA</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">deep</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># reshape the data such that one time step is a 1-D vector</span>
<span class="c1"># i.e. the feature_unscaled array is hence 2-D (timestep, number of grid points)</span>
<span class="n">feature_unscaled</span> <span class="o">=</span> <span class="n">feature</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">feature</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">label_unscaled</span> <span class="o">=</span> <span class="n">label</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">label</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># scale the data</span>
<span class="n">scaler_f</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">Xorg</span> <span class="o">=</span> <span class="n">scaler_f</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">feature_unscaled</span><span class="p">)</span>

<span class="n">scaler_l</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">yorg</span> <span class="o">=</span> <span class="n">scaler_l</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">label_unscaled</span><span class="p">)</span>

<span class="c1"># replace nans with 0</span>
<span class="n">Xall</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan_to_num</span><span class="p">(</span><span class="n">Xorg</span><span class="p">)</span>
<span class="n">yall</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan_to_num</span><span class="p">(</span><span class="n">yorg</span><span class="p">)</span>

<span class="c1"># shift = 3 is needed to align with the usual way how lead time is defined</span>
<span class="n">shift</span> <span class="o">=</span> <span class="mi">3</span>

<span class="c1"># the lead time</span>
<span class="n">lead</span> <span class="o">=</span> <span class="mi">3</span>

<span class="n">y</span> <span class="o">=</span> <span class="n">yall</span><span class="p">[</span><span class="n">lead</span><span class="o">+</span><span class="n">shift</span><span class="p">:]</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">Xall</span><span class="p">[:</span><span class="o">-</span><span class="n">lead</span><span class="o">-</span><span class="n">shift</span><span class="p">]</span>
<span class="n">timey</span> <span class="o">=</span> <span class="n">oni</span><span class="o">.</span><span class="n">index</span><span class="p">[</span><span class="n">lead</span><span class="o">+</span><span class="n">shift</span><span class="p">:]</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/home/paul/miniconda2/envs/ninolearn/lib/python3.6/site-packages/sklearn/utils/extmath.py:747: RuntimeWarning: invalid value encountered in true_divide
  updated_mean = (last_sum + new_sum) / updated_sample_count
/home/paul/miniconda2/envs/ninolearn/lib/python3.6/site-packages/sklearn/utils/extmath.py:688: RuntimeWarning: Degrees of freedom &lt;= 0 for slice.
  result = op(x, *args, **kwargs)
/home/paul/miniconda2/envs/ninolearn/lib/python3.6/site-packages/sklearn/utils/extmath.py:747: RuntimeWarning: invalid value encountered in true_divide
  updated_mean = (last_sum + new_sum) / updated_sample_count
/home/paul/miniconda2/envs/ninolearn/lib/python3.6/site-packages/sklearn/utils/extmath.py:688: RuntimeWarning: Degrees of freedom &lt;= 0 for slice.
  result = op(x, *args, **kwargs)
</pre></div></div>
</div>
</div>
<div class="section" id="Split-the-data-set">
<h2>Split the data set<a class="headerlink" href="#Split-the-data-set" title="Permalink to this headline">¶</a></h2>
<p>For the training and testing of machine learning models it is crucial to split the data set into:</p>
<ol class="arabic simple">
<li><p><strong>Train data set</strong> which is used to train the weights of the neural network</p></li>
<li><p><strong>Validation data set</strong> which is used to check for overfitting (e.g. when using early stopping) and to optimize the hyperparameters</p></li>
<li><p><strong>Test data set</strong> which is used to to evaluate the trained model.</p></li>
</ol>
<p><strong>NOTE:</strong> It is important to understand that hyperparamters must be tuned so that the result is best for the Validation data set and <strong>not</strong> for the test data set. Otherwise you can not rule out the case that the specific hyperparameter setting just works good for the specific test data set but is not generally a good hyperparameter setting.</p>
<p>In the following cell the train and the validation data set are still one data set, because this array will be later splitted into two arrays when th model is fitted.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">test_indeces</span> <span class="o">=</span> <span class="n">test_indeces</span> <span class="o">=</span> <span class="p">(</span><span class="n">timey</span><span class="o">&gt;=</span><span class="s1">&#39;2001-01-01&#39;</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">timey</span><span class="o">&lt;=</span><span class="s1">&#39;2018-12-01&#39;</span><span class="p">)</span>
<span class="n">train_val_indeces</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">invert</span><span class="p">(</span><span class="n">test_indeces</span><span class="p">)</span>

<span class="n">train_val_X</span><span class="p">,</span> <span class="n">train_val_y</span><span class="p">,</span> <span class="n">train_val_timey</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">train_val_indeces</span><span class="p">,:],</span> <span class="n">y</span><span class="p">[</span><span class="n">train_val_indeces</span><span class="p">,:],</span> <span class="n">timey</span><span class="p">[</span><span class="n">train_val_indeces</span><span class="p">]</span>
<span class="n">testX</span><span class="p">,</span> <span class="n">testy</span><span class="p">,</span> <span class="n">testtimey</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">test_indeces</span><span class="p">,:],</span> <span class="n">y</span><span class="p">[</span><span class="n">test_indeces</span><span class="p">,:],</span> <span class="n">timey</span><span class="p">[</span><span class="n">test_indeces</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Fit-the-model">
<h2>Fit the model<a class="headerlink" href="#Fit-the-model" title="Permalink to this headline">¶</a></h2>
<p>Let’s train the model using a random search. This takes quite some time (for <code class="docutils literal notranslate"><span class="pre">n_iter=100</span></code> it took an our on my local machine without GPU support). In this training process the train/validation data set will be splitted In this example below this train/validation data is first divided into 5 segments (<code class="docutils literal notranslate"><span class="pre">n_segments=5</span></code>). One segment alwawys serves as the validation data set and the rest as training. Each segment is one time (<code class="docutils literal notranslate"><span class="pre">n_members_segment=1</span></code>) the validation data set. Hence, the ensemble
consists in the end out of 5 models.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">keras.backend</span> <span class="k">as</span> <span class="nn">K</span>
<span class="kn">from</span> <span class="nn">ninolearn.learn.models.encoderDecoder</span> <span class="k">import</span> <span class="n">EncoderDecoder</span>

<span class="n">K</span><span class="o">.</span><span class="n">clear_session</span><span class="p">()</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">EncoderDecoder</span><span class="p">()</span>

<span class="n">model</span><span class="o">.</span><span class="n">set_parameters</span><span class="p">(</span><span class="n">neurons</span><span class="o">=</span><span class="p">[(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">8</span><span class="p">),</span> <span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">64</span><span class="p">)],</span> <span class="n">dropout</span><span class="o">=</span><span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">],</span> <span class="n">noise</span><span class="o">=</span><span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">]</span> <span class="p">,</span> <span class="n">noise_out</span><span class="o">=</span><span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span>
         <span class="n">l1_hidden</span><span class="o">=</span><span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.001</span><span class="p">],</span> <span class="n">l2_hidden</span><span class="o">=</span><span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.001</span><span class="p">],</span> <span class="n">l1_out</span><span class="o">=</span><span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.001</span><span class="p">],</span> <span class="n">l2_out</span><span class="o">=</span><span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.001</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
         <span class="n">lr</span><span class="o">=</span><span class="p">[</span><span class="mf">0.0001</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">],</span> <span class="n">n_segments</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">n_members_segment</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">patience</span> <span class="o">=</span> <span class="mi">40</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">fit_RandomizedSearch</span><span class="p">(</span><span class="n">train_val_X</span><span class="p">,</span> <span class="n">train_val_y</span><span class="p">,</span> <span class="n">n_iter</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Using TensorFlow backend.
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

##################################################################
Search iteration Nr 1/100
##################################################################

Train member Nr 1/5
--------------------------------------
WARNING:tensorflow:From /home/paul/miniconda2/envs/ninolearn/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /home/paul/miniconda2/envs/ninolearn/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
Restoring model weights from the end of the best epoch
Epoch 00231: early stopping
97/97 [==============================] - 0s 174us/step
Loss: 0.606672500212168
Train member Nr 2/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00062: early stopping
97/97 [==============================] - 0s 144us/step
Loss: 0.8190183221679372
Train member Nr 3/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00075: early stopping
97/97 [==============================] - 0s 147us/step
Loss: 0.5666148499729707
Train member Nr 4/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00055: early stopping
97/97 [==============================] - 0s 178us/step
Loss: 0.5022133576501276
Train member Nr 5/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00224: early stopping
97/97 [==============================] - 0s 144us/step
Loss: 0.7257455707210856
Mean loss: 0.6440529201448578
New best hyperparameters
--------------------------------------
Mean loss: 0.6440529201448578
{&#39;neurons&#39;: (115, 40), &#39;dropout&#39;: 0.096778452998804, &#39;noise&#39;: 0.32317924109898233, &#39;noise_out&#39;: 0.4732234272066452, &#39;l1_hidden&#39;: 0.0004608075916238662, &#39;l2_hidden&#39;: 0.0004222331619876754, &#39;l1_out&#39;: 0.00022723778925678496, &#39;l2_out&#39;: 0.0004727670739600789, &#39;lr&#39;: 0.0004888231261999222, &#39;batch_size&#39;: 100}

##################################################################
Search iteration Nr 2/100
##################################################################

Train member Nr 1/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00086: early stopping
97/97 [==============================] - 0s 199us/step
Loss: 0.5954928600911013
Train member Nr 2/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00095: early stopping
97/97 [==============================] - 0s 152us/step
Loss: 0.8003881358608758
Train member Nr 3/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00065: early stopping
97/97 [==============================] - 0s 119us/step
Loss: 0.5514511284754449
Train member Nr 4/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00091: early stopping
97/97 [==============================] - 0s 143us/step
Loss: 0.49608864612186077
Train member Nr 5/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00101: early stopping
97/97 [==============================] - 0s 131us/step
Loss: 0.8240596897823295
Mean loss: 0.6534960920663224

##################################################################
Search iteration Nr 3/100
##################################################################

Train member Nr 1/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00124: early stopping
97/97 [==============================] - 0s 228us/step
Loss: 0.5686127998165249
Train member Nr 2/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00072: early stopping
97/97 [==============================] - 0s 293us/step
Loss: 0.783138189119162
Train member Nr 3/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00055: early stopping
97/97 [==============================] - 0s 224us/step
Loss: 0.5525715172905283
Train member Nr 4/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00090: early stopping
97/97 [==============================] - 0s 231us/step
Loss: 0.4910680178514461
Train member Nr 5/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00091: early stopping
97/97 [==============================] - 0s 229us/step
Loss: 0.8227460753057421
Mean loss: 0.6436273198766806
New best hyperparameters
--------------------------------------
Mean loss: 0.6436273198766806
{&#39;neurons&#39;: (358, 24), &#39;dropout&#39;: 0.15999059175503463, &#39;noise&#39;: 0.14186665664706982, &#39;noise_out&#39;: 0.32329776833196106, &#39;l1_hidden&#39;: 0.00041604066708110765, &#39;l2_hidden&#39;: 0.0007073477322080547, &#39;l1_out&#39;: 0.0009040118623627197, &#39;l2_out&#39;: 0.00016894683439016788, &#39;lr&#39;: 0.00794006486644386, &#39;batch_size&#39;: 100}

##################################################################
Search iteration Nr 4/100
##################################################################

Train member Nr 1/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00098: early stopping
97/97 [==============================] - 0s 266us/step
Loss: 0.5767661824668806
Train member Nr 2/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00155: early stopping
97/97 [==============================] - 0s 191us/step
Loss: 0.7224303619148805
Train member Nr 3/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00095: early stopping
97/97 [==============================] - 0s 222us/step
Loss: 0.5495931994669216
Train member Nr 4/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00063: early stopping
97/97 [==============================] - 0s 184us/step
Loss: 0.5016216746310598
Train member Nr 5/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00170: early stopping
97/97 [==============================] - 0s 188us/step
Loss: 0.7145157929548284
Mean loss: 0.6129854422869142
New best hyperparameters
--------------------------------------
Mean loss: 0.6129854422869142
{&#39;neurons&#39;: (291, 28), &#39;dropout&#39;: 0.1431755671115358, &#39;noise&#39;: 0.0013436770698335154, &#39;noise_out&#39;: 0.044187953695428994, &#39;l1_hidden&#39;: 0.00048770934604050453, &#39;l2_hidden&#39;: 0.0004715680269068451, &#39;l1_out&#39;: 0.0005451882364499125, &#39;l2_out&#39;: 0.00044506034982592067, &#39;lr&#39;: 0.00461328522575661, &#39;batch_size&#39;: 100}

##################################################################
Search iteration Nr 5/100
##################################################################

Train member Nr 1/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00136: early stopping
97/97 [==============================] - 0s 196us/step
Loss: 0.5942402746259552
Train member Nr 2/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00205: early stopping
97/97 [==============================] - 0s 179us/step
Loss: 0.8169717075898475
Train member Nr 3/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00115: early stopping
97/97 [==============================] - 0s 210us/step
Loss: 0.5612832310887956
Train member Nr 4/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00057: early stopping
97/97 [==============================] - 0s 181us/step
Loss: 0.5093760293783601
Train member Nr 5/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00057: early stopping
97/97 [==============================] - 0s 201us/step
Loss: 0.8314401866848936
Mean loss: 0.6626622858735705

##################################################################
Search iteration Nr 6/100
##################################################################

Train member Nr 1/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00074: early stopping
97/97 [==============================] - 0s 265us/step
Loss: 0.5802521502848753
Train member Nr 2/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00136: early stopping
97/97 [==============================] - 0s 139us/step
Loss: 0.719352242872887
Train member Nr 3/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00071: early stopping
97/97 [==============================] - 0s 151us/step
Loss: 0.5354131420248562
Train member Nr 4/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00056: early stopping
97/97 [==============================] - 0s 153us/step
Loss: 0.5020431138805508
Train member Nr 5/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00177: early stopping
97/97 [==============================] - 0s 176us/step
Loss: 0.7450924681634018
Mean loss: 0.6164306234453143

##################################################################
Search iteration Nr 7/100
##################################################################

Train member Nr 1/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00105: early stopping
97/97 [==============================] - 0s 173us/step
Loss: 0.5728608474289019
Train member Nr 2/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00048: early stopping
97/97 [==============================] - 0s 236us/step
Loss: 0.7196937307869036
Train member Nr 3/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00052: early stopping
97/97 [==============================] - 0s 159us/step
Loss: 0.5343079656055293
Train member Nr 4/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00085: early stopping
97/97 [==============================] - 0s 166us/step
Loss: 0.4806606615941549
Train member Nr 5/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00105: early stopping
97/97 [==============================] - 0s 154us/step
Loss: 0.6744321732176948
Mean loss: 0.5963910757266369
New best hyperparameters
--------------------------------------
Mean loss: 0.5963910757266369
{&#39;neurons&#39;: (182, 27), &#39;dropout&#39;: 0.14701184667627873, &#39;noise&#39;: 0.47310195887639966, &#39;noise_out&#39;: 0.39970232399476907, &#39;l1_hidden&#39;: 0.0005788402233340221, &#39;l2_hidden&#39;: 0.00016721581465872637, &#39;l1_out&#39;: 0.00012507893039011254, &#39;l2_out&#39;: 0.00037851623554726335, &#39;lr&#39;: 0.008440858829299836, &#39;batch_size&#39;: 100}

##################################################################
Search iteration Nr 8/100
##################################################################

Train member Nr 1/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00056: early stopping
97/97 [==============================] - 0s 181us/step
Loss: 0.600658961792582
Train member Nr 2/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00063: early stopping
97/97 [==============================] - 0s 153us/step
Loss: 0.7354535460472107
Train member Nr 3/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00049: early stopping
97/97 [==============================] - 0s 145us/step
Loss: 0.5489317120350513
Train member Nr 4/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00043: early stopping
97/97 [==============================] - 0s 219us/step
Loss: 0.49184974690073546
Train member Nr 5/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00063: early stopping
97/97 [==============================] - 0s 176us/step
Loss: 0.6997109009433038
Mean loss: 0.6153209735437766

##################################################################
Search iteration Nr 9/100
##################################################################

Train member Nr 1/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00241: early stopping
97/97 [==============================] - 0s 102us/step
Loss: 0.6081758067779934
Train member Nr 2/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00203: early stopping
97/97 [==============================] - 0s 106us/step
Loss: 0.8589829931554106
Train member Nr 3/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00098: early stopping
97/97 [==============================] - 0s 106us/step
Loss: 0.5681723479143123
Train member Nr 4/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00095: early stopping
97/97 [==============================] - 0s 97us/step
Loss: 0.5065507108403235
Train member Nr 5/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00138: early stopping
97/97 [==============================] - 0s 110us/step
Loss: 0.8356900808122969
Mean loss: 0.6755143879000673

##################################################################
Search iteration Nr 10/100
##################################################################

Train member Nr 1/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00198: early stopping
97/97 [==============================] - 0s 80us/step
Loss: 0.5961801932030117
Train member Nr 2/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00121: early stopping
97/97 [==============================] - 0s 84us/step
Loss: 0.8544701442276079
Train member Nr 3/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00110: early stopping
97/97 [==============================] - 0s 102us/step
Loss: 0.5614131470930945
Train member Nr 4/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00082: early stopping
97/97 [==============================] - 0s 91us/step
Loss: 0.5177339843867981
Train member Nr 5/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00170: early stopping
97/97 [==============================] - 0s 90us/step
Loss: 0.8416371751077396
Mean loss: 0.6742869288036504

##################################################################
Search iteration Nr 11/100
##################################################################

Train member Nr 1/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00061: early stopping
97/97 [==============================] - 0s 309us/step
Loss: 0.5969452268069553
Train member Nr 2/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00060: early stopping
97/97 [==============================] - 0s 283us/step
Loss: 0.7354880485338035
Train member Nr 3/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00045: early stopping
97/97 [==============================] - 0s 287us/step
Loss: 0.5435341627327437
Train member Nr 4/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00047: early stopping
97/97 [==============================] - 0s 287us/step
Loss: 0.49608362704208214
Train member Nr 5/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00159: early stopping
97/97 [==============================] - 0s 517us/step
Loss: 0.6663930084287506
Mean loss: 0.607688814708867

##################################################################
Search iteration Nr 12/100
##################################################################

Train member Nr 1/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00097: early stopping
97/97 [==============================] - 0s 170us/step
Loss: 0.5807164139354352
Train member Nr 2/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00129: early stopping
97/97 [==============================] - 0s 174us/step
Loss: 0.7645499890612573
Train member Nr 3/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00111: early stopping
97/97 [==============================] - 0s 175us/step
Loss: 0.5404430114731347
Train member Nr 4/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00095: early stopping
97/97 [==============================] - 0s 162us/step
Loss: 0.49704948036941055
Train member Nr 5/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00134: early stopping
97/97 [==============================] - 0s 195us/step
Loss: 0.8290092840637129
Mean loss: 0.6423536357805901

##################################################################
Search iteration Nr 13/100
##################################################################

Train member Nr 1/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00053: early stopping
97/97 [==============================] - 0s 169us/step
Loss: 0.5936577572036035
Train member Nr 2/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00051: early stopping
97/97 [==============================] - 0s 181us/step
Loss: 0.7345607342179289
Train member Nr 3/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00048: early stopping
97/97 [==============================] - 0s 190us/step
Loss: 0.5458237372108341
Train member Nr 4/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00047: early stopping
97/97 [==============================] - 0s 164us/step
Loss: 0.49737350166458444
Train member Nr 5/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00074: early stopping
97/97 [==============================] - 0s 169us/step
Loss: 0.6704271810570943
Mean loss: 0.6083685822708091

##################################################################
Search iteration Nr 14/100
##################################################################

Train member Nr 1/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00067: early stopping
97/97 [==============================] - 0s 89us/step
Loss: 0.6717166660987225
Train member Nr 2/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00100: early stopping
97/97 [==============================] - 0s 221us/step
Loss: 0.8134843602622908
Train member Nr 3/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00101: early stopping
97/97 [==============================] - 0s 95us/step
Loss: 0.5331315634791384
Train member Nr 4/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00082: early stopping
97/97 [==============================] - 0s 178us/step
Loss: 0.5151580025240318
Train member Nr 5/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00118: early stopping
97/97 [==============================] - 0s 97us/step
Loss: 0.8550603801442176
Mean loss: 0.6777101945016802

##################################################################
Search iteration Nr 15/100
##################################################################

Train member Nr 1/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00047: early stopping
97/97 [==============================] - 0s 103us/step
Loss: 0.5886969222235925
Train member Nr 2/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00053: early stopping
97/97 [==============================] - 0s 107us/step
Loss: 0.7090771702147022
Train member Nr 3/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00060: early stopping
97/97 [==============================] - 0s 183us/step
Loss: 0.5505245269573841
Train member Nr 4/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00051: early stopping
97/97 [==============================] - 0s 139us/step
Loss: 0.5046293624897593
Train member Nr 5/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00050: early stopping
97/97 [==============================] - 0s 110us/step
Loss: 0.6863506374899874
Mean loss: 0.6078557238750851

##################################################################
Search iteration Nr 16/100
##################################################################

Train member Nr 1/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00089: early stopping
97/97 [==============================] - 0s 257us/step
Loss: 0.5924794157755744
Train member Nr 2/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00108: early stopping
97/97 [==============================] - 0s 244us/step
Loss: 0.7876087470152944
Train member Nr 3/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00127: early stopping
97/97 [==============================] - 0s 310us/step
Loss: 0.556469687174276
Train member Nr 4/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00066: early stopping
97/97 [==============================] - 0s 266us/step
Loss: 0.4933066706067508
Train member Nr 5/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00099: early stopping
97/97 [==============================] - 0s 254us/step
Loss: 0.814497670561997
Mean loss: 0.6488724382267785

##################################################################
Search iteration Nr 17/100
##################################################################

Train member Nr 1/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00046: early stopping
97/97 [==============================] - 0s 95us/step
Loss: 0.5822775259460371
Train member Nr 2/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00081: early stopping
97/97 [==============================] - 0s 85us/step
Loss: 0.7207241875609172
Train member Nr 3/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00083: early stopping
97/97 [==============================] - 0s 88us/step
Loss: 0.5429654066095647
Train member Nr 4/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00046: early stopping
97/97 [==============================] - 0s 93us/step
Loss: 0.4946127619939981
Train member Nr 5/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00054: early stopping
97/97 [==============================] - 0s 89us/step
Loss: 0.6774657297994673
Mean loss: 0.6036091223819968

##################################################################
Search iteration Nr 18/100
##################################################################

Train member Nr 1/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00132: early stopping
97/97 [==============================] - 0s 243us/step
Loss: 0.5725130727610637
Train member Nr 2/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00068: early stopping
97/97 [==============================] - 0s 286us/step
Loss: 0.8140584562242645
Train member Nr 3/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00062: early stopping
97/97 [==============================] - 0s 234us/step
Loss: 0.5440732013318956
Train member Nr 4/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00092: early stopping
97/97 [==============================] - 0s 212us/step
Loss: 0.4995226995232179
Train member Nr 5/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00118: early stopping
97/97 [==============================] - 0s 208us/step
Loss: 0.821154256456906
Mean loss: 0.6502643372594695

##################################################################
Search iteration Nr 19/100
##################################################################

Train member Nr 1/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00058: early stopping
97/97 [==============================] - 0s 99us/step
Loss: 0.5999376011877945
Train member Nr 2/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00045: early stopping
97/97 [==============================] - 0s 95us/step
Loss: 0.7636859152734894
Train member Nr 3/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00075: early stopping
97/97 [==============================] - 0s 89us/step
Loss: 0.5499418135156336
Train member Nr 4/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00069: early stopping
97/97 [==============================] - 0s 104us/step
Loss: 0.49555183685931964
Train member Nr 5/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00219: early stopping
97/97 [==============================] - 0s 99us/step
Loss: 0.6966151373902547
Mean loss: 0.6211464608452983

##################################################################
Search iteration Nr 20/100
##################################################################

Train member Nr 1/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00052: early stopping
97/97 [==============================] - 0s 131us/step
Loss: 0.6100911362883971
Train member Nr 2/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00103: early stopping
97/97 [==============================] - 0s 112us/step
Loss: 0.7478838446214027
Train member Nr 3/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00049: early stopping
97/97 [==============================] - 0s 124us/step
Loss: 0.5487093836376348
Train member Nr 4/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00045: early stopping
97/97 [==============================] - 0s 120us/step
Loss: 0.4938477001239344
Train member Nr 5/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00105: early stopping
97/97 [==============================] - 0s 194us/step
Loss: 0.7085413536460129
Mean loss: 0.6218146836634764

##################################################################
Search iteration Nr 21/100
##################################################################

Train member Nr 1/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00046: early stopping
97/97 [==============================] - 0s 267us/step
Loss: 0.6056418566359687
Train member Nr 2/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00053: early stopping
97/97 [==============================] - 0s 271us/step
Loss: 0.7520466901592373
Train member Nr 3/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00047: early stopping
97/97 [==============================] - 0s 342us/step
Loss: 0.5538966972188851
Train member Nr 4/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00051: early stopping
97/97 [==============================] - 0s 384us/step
Loss: 0.50676430685004
Train member Nr 5/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00099: early stopping
97/97 [==============================] - 0s 477us/step
Loss: 0.6873551846779499
Mean loss: 0.6211409471084163

##################################################################
Search iteration Nr 22/100
##################################################################

Train member Nr 1/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00086: early stopping
97/97 [==============================] - 0s 197us/step
Loss: 0.6043200081156701
Train member Nr 2/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00071: early stopping
97/97 [==============================] - 0s 131us/step
Loss: 0.8236175271653637
Train member Nr 3/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00068: early stopping
97/97 [==============================] - 0s 210us/step
Loss: 0.5614804637800787
Train member Nr 4/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00054: early stopping
97/97 [==============================] - 0s 136us/step
Loss: 0.5021053921316088
Train member Nr 5/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00520: early stopping
97/97 [==============================] - 0s 129us/step
Loss: 0.7034275528696394
Mean loss: 0.6389901888124722

##################################################################
Search iteration Nr 23/100
##################################################################

Train member Nr 1/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00054: early stopping
97/97 [==============================] - 0s 231us/step
Loss: 0.5924564114550954
Train member Nr 2/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00052: early stopping
97/97 [==============================] - 0s 240us/step
Loss: 0.7635484565164625
Train member Nr 3/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00047: early stopping
97/97 [==============================] - 0s 224us/step
Loss: 0.5562869150614002
Train member Nr 4/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00051: early stopping
97/97 [==============================] - 0s 300us/step
Loss: 0.4969098819899805
Train member Nr 5/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00111: early stopping
97/97 [==============================] - 0s 229us/step
Loss: 0.6922078366132126
Mean loss: 0.6202819003272303

##################################################################
Search iteration Nr 24/100
##################################################################

Train member Nr 1/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00238: early stopping
97/97 [==============================] - 0s 246us/step
Loss: 0.5932843255013535
Train member Nr 2/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00209: early stopping
97/97 [==============================] - 0s 184us/step
Loss: 0.7376477509429774
Train member Nr 3/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00055: early stopping
97/97 [==============================] - 0s 357us/step
Loss: 0.5578306437153178
Train member Nr 4/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00089: early stopping
97/97 [==============================] - 0s 192us/step
Loss: 0.49796522462490905
Train member Nr 5/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00185: early stopping
97/97 [==============================] - 0s 192us/step
Loss: 0.7121153264930568
Mean loss: 0.619768654255523

##################################################################
Search iteration Nr 25/100
##################################################################

Train member Nr 1/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00203: early stopping
97/97 [==============================] - 0s 125us/step
Loss: 0.6557291604808926
Train member Nr 2/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00046: early stopping
97/97 [==============================] - 0s 178us/step
Loss: 1.1063904233814514
Train member Nr 3/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00081: early stopping
97/97 [==============================] - 0s 215us/step
Loss: 0.5702808603797991
Train member Nr 4/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00059: early stopping
97/97 [==============================] - 0s 147us/step
Loss: 0.5262169979282261
Train member Nr 5/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00068: early stopping
97/97 [==============================] - 0s 134us/step
Loss: 0.8886670273603853
Mean loss: 0.749456893906151

##################################################################
Search iteration Nr 26/100
##################################################################

Train member Nr 1/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00205: early stopping
97/97 [==============================] - 0s 262us/step
Loss: 0.6468885442645279
Train member Nr 2/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00057: early stopping
97/97 [==============================] - 0s 250us/step
Loss: 0.798652094664033
Train member Nr 3/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00054: early stopping
97/97 [==============================] - 0s 270us/step
Loss: 0.5649716617520323
Train member Nr 4/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00060: early stopping
97/97 [==============================] - 0s 304us/step
Loss: 0.49276089483929664
Train member Nr 5/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00052: early stopping
97/97 [==============================] - 0s 263us/step
Loss: 0.8864230046567229
Mean loss: 0.6779392400353225

##################################################################
Search iteration Nr 27/100
##################################################################

Train member Nr 1/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00049: early stopping
97/97 [==============================] - 0s 215us/step
Loss: 0.5607224653676613
Train member Nr 2/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00102: early stopping
97/97 [==============================] - 0s 298us/step
Loss: 0.6945107278135634
Train member Nr 3/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00055: early stopping
97/97 [==============================] - 0s 271us/step
Loss: 0.5513546918470835
Train member Nr 4/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00047: early stopping
97/97 [==============================] - 0s 317us/step
Loss: 0.49957835797182065
Train member Nr 5/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00057: early stopping
97/97 [==============================] - 0s 241us/step
Loss: 0.7138227316522107
Mean loss: 0.603997794930468

##################################################################
Search iteration Nr 28/100
##################################################################

Train member Nr 1/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00046: early stopping
97/97 [==============================] - 0s 274us/step
Loss: 0.5942006510557588
Train member Nr 2/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00053: early stopping
97/97 [==============================] - 0s 338us/step
Loss: 0.7081148120545849
Train member Nr 3/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00053: early stopping
97/97 [==============================] - 0s 246us/step
Loss: 0.5538357047690559
Train member Nr 4/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00052: early stopping
97/97 [==============================] - 0s 234us/step
Loss: 0.49465610378796293
Train member Nr 5/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00051: early stopping
97/97 [==============================] - 0s 333us/step
Loss: 0.6772730116991653
Mean loss: 0.6056160566733055

##################################################################
Search iteration Nr 29/100
##################################################################

Train member Nr 1/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00070: early stopping
97/97 [==============================] - 0s 205us/step
Loss: 0.6000572092754325
Train member Nr 2/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00097: early stopping
97/97 [==============================] - 0s 224us/step
Loss: 0.7490771849130847
Train member Nr 3/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00060: early stopping
97/97 [==============================] - 0s 174us/step
Loss: 0.553182325719558
Train member Nr 4/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00054: early stopping
97/97 [==============================] - 0s 207us/step
Loss: 0.49026307064233365
Train member Nr 5/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00104: early stopping
97/97 [==============================] - 0s 186us/step
Loss: 0.6839093246410802
Mean loss: 0.6152978230382977

##################################################################
Search iteration Nr 30/100
##################################################################

Train member Nr 1/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00057: early stopping
97/97 [==============================] - 0s 197us/step
Loss: 0.5705882040495726
Train member Nr 2/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00084: early stopping
97/97 [==============================] - 0s 190us/step
Loss: 0.743363467688413
Train member Nr 3/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00047: early stopping
97/97 [==============================] - 0s 194us/step
Loss: 0.5465228619034758
Train member Nr 4/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00054: early stopping
97/97 [==============================] - 0s 200us/step
Loss: 0.49675043219143583
Train member Nr 5/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00140: early stopping
97/97 [==============================] - 0s 196us/step
Loss: 0.7079285503048258
Mean loss: 0.6130307032275446

##################################################################
Search iteration Nr 31/100
##################################################################

Train member Nr 1/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00076: early stopping
97/97 [==============================] - 0s 160us/step
Loss: 0.5891964650645698
Train member Nr 2/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00089: early stopping
97/97 [==============================] - 0s 158us/step
Loss: 0.7322585760932607
Train member Nr 3/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00049: early stopping
97/97 [==============================] - 0s 205us/step
Loss: 0.5430942826049844
Train member Nr 4/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00047: early stopping
97/97 [==============================] - 0s 165us/step
Loss: 0.49609241288961825
Train member Nr 5/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00075: early stopping
97/97 [==============================] - 0s 157us/step
Loss: 0.6738318828577848
Mean loss: 0.6068947239020437

##################################################################
Search iteration Nr 32/100
##################################################################

Train member Nr 1/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00106: early stopping
97/97 [==============================] - 0s 190us/step
Loss: 0.5940004169326467
Train member Nr 2/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00067: early stopping
97/97 [==============================] - 0s 205us/step
Loss: 0.8042498691794798
Train member Nr 3/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00096: early stopping
97/97 [==============================] - 0s 307us/step
Loss: 0.5491026670662398
Train member Nr 4/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00081: early stopping
97/97 [==============================] - 0s 178us/step
Loss: 0.5015687205127835
Train member Nr 5/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00337: early stopping
97/97 [==============================] - 0s 195us/step
Loss: 0.6931977093834238
Mean loss: 0.6284238766149146

##################################################################
Search iteration Nr 33/100
##################################################################

Train member Nr 1/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00045: early stopping
97/97 [==============================] - 0s 119us/step
Loss: 0.6296356793531438
Train member Nr 2/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00046: early stopping
97/97 [==============================] - 0s 190us/step
Loss: 0.7496499953810701
Train member Nr 3/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00047: early stopping
97/97 [==============================] - 0s 118us/step
Loss: 0.5675219638445943
Train member Nr 4/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00047: early stopping
97/97 [==============================] - 0s 137us/step
Loss: 0.5098338901382131
Train member Nr 5/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00048: early stopping
97/97 [==============================] - 0s 130us/step
Loss: 0.7117926174217892
Mean loss: 0.6336868292277622

##################################################################
Search iteration Nr 34/100
##################################################################

Train member Nr 1/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00056: early stopping
97/97 [==============================] - 0s 77us/step
Loss: 0.6068318271145379
Train member Nr 2/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00115: early stopping
97/97 [==============================] - 0s 93us/step
Loss: 0.7735648785055298
Train member Nr 3/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00049: early stopping
97/97 [==============================] - 0s 80us/step
Loss: 0.5497487122865067
Train member Nr 4/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00045: early stopping
97/97 [==============================] - 0s 86us/step
Loss: 0.5044783888403902
Train member Nr 5/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00071: early stopping
97/97 [==============================] - 0s 108us/step
Loss: 0.6812975855217767
Mean loss: 0.6231842784537482

##################################################################
Search iteration Nr 35/100
##################################################################

Train member Nr 1/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00063: early stopping
97/97 [==============================] - 0s 191us/step
Loss: 0.5970564920877673
Train member Nr 2/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00121: early stopping
97/97 [==============================] - 0s 133us/step
Loss: 0.7569379185892872
Train member Nr 3/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00063: early stopping
97/97 [==============================] - 0s 215us/step
Loss: 0.55448143168823
Train member Nr 4/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00077: early stopping
97/97 [==============================] - 0s 146us/step
Loss: 0.49481259424661855
Train member Nr 5/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00177: early stopping
97/97 [==============================] - 0s 139us/step
Loss: 0.7199032868921142
Mean loss: 0.6246383447008034

##################################################################
Search iteration Nr 36/100
##################################################################

Train member Nr 1/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00082: early stopping
97/97 [==============================] - 0s 107us/step
Loss: 0.5940249377919227
Train member Nr 2/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00043: early stopping
97/97 [==============================] - 0s 105us/step
Loss: 0.7787535092265335
Train member Nr 3/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00049: early stopping
97/97 [==============================] - 0s 112us/step
Loss: 0.5463809911737737
Train member Nr 4/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00092: early stopping
97/97 [==============================] - 0s 95us/step
Loss: 0.5040673687285984
Train member Nr 5/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00159: early stopping
97/97 [==============================] - 0s 94us/step
Loss: 0.7635295394155168
Mean loss: 0.637351269267269

##################################################################
Search iteration Nr 37/100
##################################################################

Train member Nr 1/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00044: early stopping
97/97 [==============================] - 0s 137us/step
Loss: 0.5875322714294355
Train member Nr 2/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00084: early stopping
97/97 [==============================] - 0s 140us/step
Loss: 0.7319064478284305
Train member Nr 3/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00045: early stopping
97/97 [==============================] - 0s 163us/step
Loss: 0.5497325314688928
Train member Nr 4/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00044: early stopping
97/97 [==============================] - 0s 152us/step
Loss: 0.49290644016462504
Train member Nr 5/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00067: early stopping
97/97 [==============================] - 0s 151us/step
Loss: 0.6895254318861618
Mean loss: 0.6103206245555091

##################################################################
Search iteration Nr 38/100
##################################################################

Train member Nr 1/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00082: early stopping
97/97 [==============================] - 0s 233us/step
Loss: 0.5953706072777817
Train member Nr 2/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00096: early stopping
97/97 [==============================] - 0s 234us/step
Loss: 0.7176401498391456
Train member Nr 3/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00053: early stopping
97/97 [==============================] - 0s 237us/step
Loss: 0.5440706979368151
Train member Nr 4/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00049: early stopping
97/97 [==============================] - 0s 227us/step
Loss: 0.4932528672759066
Train member Nr 5/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00087: early stopping
97/97 [==============================] - 0s 248us/step
Loss: 0.6834160452036514
Mean loss: 0.60675007350666

##################################################################
Search iteration Nr 39/100
##################################################################

Train member Nr 1/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00061: early stopping
97/97 [==============================] - 0s 93us/step
Loss: 0.6144141941955409
Train member Nr 2/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00062: early stopping
97/97 [==============================] - 0s 95us/step
Loss: 0.7514696735696694
Train member Nr 3/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00052: early stopping
97/97 [==============================] - 0s 92us/step
Loss: 0.5580751195396345
Train member Nr 4/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00048: early stopping
97/97 [==============================] - 0s 92us/step
Loss: 0.5019844186674688
Train member Nr 5/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00076: early stopping
97/97 [==============================] - 0s 146us/step
Loss: 0.6727554942529226
Mean loss: 0.6197397800450473

##################################################################
Search iteration Nr 40/100
##################################################################

Train member Nr 1/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00063: early stopping
97/97 [==============================] - 0s 174us/step
Loss: 0.5839207436620575
Train member Nr 2/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00043: early stopping
97/97 [==============================] - 0s 141us/step
Loss: 0.7254873102473229
Train member Nr 3/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00073: early stopping
97/97 [==============================] - 0s 169us/step
Loss: 0.52710814482158
Train member Nr 4/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00049: early stopping
97/97 [==============================] - 0s 251us/step
Loss: 0.49298097976704236
Train member Nr 5/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00095: early stopping
97/97 [==============================] - 0s 157us/step
Loss: 0.6713992025434357
Mean loss: 0.6001792762082877

##################################################################
Search iteration Nr 41/100
##################################################################

Train member Nr 1/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00086: early stopping
97/97 [==============================] - 0s 130us/step
Loss: 0.5917850972450885
Train member Nr 2/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00078: early stopping
97/97 [==============================] - 0s 160us/step
Loss: 0.7059229907301283
Train member Nr 3/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00047: early stopping
97/97 [==============================] - 0s 146us/step
Loss: 0.545022148139698
Train member Nr 4/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00044: early stopping
97/97 [==============================] - 0s 143us/step
Loss: 0.5041534464383862
Train member Nr 5/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00045: early stopping
97/97 [==============================] - 0s 136us/step
Loss: 0.6848771409275606
Mean loss: 0.6063521646961723

##################################################################
Search iteration Nr 42/100
##################################################################

Train member Nr 1/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00071: early stopping
97/97 [==============================] - 0s 155us/step
Loss: 0.5820277622065593
Train member Nr 2/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00067: early stopping
97/97 [==============================] - 0s 115us/step
Loss: 0.739740779104921
Train member Nr 3/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00067: early stopping
97/97 [==============================] - 0s 130us/step
Loss: 0.5509058888425532
Train member Nr 4/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00049: early stopping
97/97 [==============================] - 0s 131us/step
Loss: 0.49397774701265945
Train member Nr 5/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00148: early stopping
97/97 [==============================] - 0s 112us/step
Loss: 0.6909975855006385
Mean loss: 0.6115299525334662

##################################################################
Search iteration Nr 43/100
##################################################################

Train member Nr 1/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00133: early stopping
97/97 [==============================] - 0s 302us/step
Loss: 0.5881253659110708
Train member Nr 2/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00059: early stopping
97/97 [==============================] - 0s 268us/step
Loss: 0.8204583187693173
Train member Nr 3/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00075: early stopping
97/97 [==============================] - 0s 249us/step
Loss: 0.548689008988056
Train member Nr 4/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00150: early stopping
97/97 [==============================] - 0s 336us/step
Loss: 0.49853202239754274
Train member Nr 5/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00235: early stopping
97/97 [==============================] - 0s 275us/step
Loss: 0.8200575101006892
Mean loss: 0.6551724452333352

##################################################################
Search iteration Nr 44/100
##################################################################

Train member Nr 1/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00084: early stopping
97/97 [==============================] - 0s 314us/step
Loss: 0.5789720440648266
Train member Nr 2/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00147: early stopping
97/97 [==============================] - 0s 288us/step
Loss: 0.710237263404217
Train member Nr 3/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00049: early stopping
97/97 [==============================] - 0s 310us/step
Loss: 0.5488470460950714
Train member Nr 4/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00068: early stopping
97/97 [==============================] - 0s 287us/step
Loss: 0.49403062739323095
Train member Nr 5/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00241: early stopping
97/97 [==============================] - 0s 294us/step
Loss: 0.7019164193536818
Mean loss: 0.6068006800622056

##################################################################
Search iteration Nr 45/100
##################################################################

Train member Nr 1/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00132: early stopping
97/97 [==============================] - 0s 92us/step
Loss: 0.5821952297515476
Train member Nr 2/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00126: early stopping
97/97 [==============================] - 0s 108us/step
Loss: 0.7662257699622321
Train member Nr 3/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00084: early stopping
97/97 [==============================] - 0s 100us/step
Loss: 0.5396042997689591
Train member Nr 4/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00069: early stopping
97/97 [==============================] - 0s 102us/step
Loss: 0.49749563342517183
Train member Nr 5/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00241: early stopping
97/97 [==============================] - 0s 90us/step
Loss: 0.7526890930441237
Mean loss: 0.6276420051904068

##################################################################
Search iteration Nr 46/100
##################################################################

Train member Nr 1/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00048: early stopping
97/97 [==============================] - 0s 131us/step
Loss: 0.5930964614927154
Train member Nr 2/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00057: early stopping
97/97 [==============================] - 0s 155us/step
Loss: 0.7425723837822983
Train member Nr 3/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00046: early stopping
97/97 [==============================] - 0s 121us/step
Loss: 0.5476003611825176
Train member Nr 4/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00047: early stopping
97/97 [==============================] - 0s 113us/step
Loss: 0.49586784470941603
Train member Nr 5/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00070: early stopping
97/97 [==============================] - 0s 108us/step
Loss: 0.6902384668895879
Mean loss: 0.613875103611307

##################################################################
Search iteration Nr 47/100
##################################################################

Train member Nr 1/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00190: early stopping
97/97 [==============================] - 0s 96us/step
Loss: 0.6058032266872445
Train member Nr 2/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00172: early stopping
97/97 [==============================] - 0s 89us/step
Loss: 0.8388914435180193
Train member Nr 3/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00090: early stopping
97/97 [==============================] - 0s 88us/step
Loss: 0.5554589871893224
Train member Nr 4/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00101: early stopping
97/97 [==============================] - 0s 94us/step
Loss: 0.50862916597386
Train member Nr 5/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00128: early stopping
97/97 [==============================] - 0s 93us/step
Loss: 0.838505720354847
Mean loss: 0.6694577087446587

##################################################################
Search iteration Nr 48/100
##################################################################

Train member Nr 1/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00045: early stopping
97/97 [==============================] - 0s 283us/step
Loss: 0.6198861414624244
Train member Nr 2/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00050: early stopping
97/97 [==============================] - 0s 285us/step
Loss: 0.758019949972015
Train member Nr 3/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00045: early stopping
97/97 [==============================] - 0s 290us/step
Loss: 0.5262427385320368
Train member Nr 4/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00048: early stopping
97/97 [==============================] - 0s 275us/step
Loss: 0.4983836025306859
Train member Nr 5/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00047: early stopping
97/97 [==============================] - 0s 281us/step
Loss: 0.7216178077397887
Mean loss: 0.6248300480473901

##################################################################
Search iteration Nr 49/100
##################################################################

Train member Nr 1/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00127: early stopping
97/97 [==============================] - 0s 248us/step
Loss: 0.5856465199559006
Train member Nr 2/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00052: early stopping
97/97 [==============================] - 0s 294us/step
Loss: 0.7865017996620887
Train member Nr 3/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00070: early stopping
97/97 [==============================] - 0s 236us/step
Loss: 0.5530495228841132
Train member Nr 4/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00094: early stopping
97/97 [==============================] - 0s 256us/step
Loss: 0.4991320592840922
Train member Nr 5/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00085: early stopping
97/97 [==============================] - 0s 224us/step
Loss: 0.8273895714700836
Mean loss: 0.6503438946512556

##################################################################
Search iteration Nr 50/100
##################################################################

Train member Nr 1/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00053: early stopping
97/97 [==============================] - 0s 159us/step
Loss: 0.608692559999289
Train member Nr 2/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00103: early stopping
97/97 [==============================] - 0s 175us/step
Loss: 0.7589441451829734
Train member Nr 3/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00083: early stopping
97/97 [==============================] - 0s 395us/step
Loss: 0.5589938818179455
Train member Nr 4/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00067: early stopping
97/97 [==============================] - 0s 180us/step
Loss: 0.4976524298953027
Train member Nr 5/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00105: early stopping
97/97 [==============================] - 0s 182us/step
Loss: 0.6911060081929276
Mean loss: 0.6230778050176877

##################################################################
Search iteration Nr 51/100
##################################################################

Train member Nr 1/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00095: early stopping
97/97 [==============================] - 0s 155us/step
Loss: 0.5960973040344789
Train member Nr 2/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00182: early stopping
97/97 [==============================] - 0s 145us/step
Loss: 0.7422546160589788
Train member Nr 3/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00059: early stopping
97/97 [==============================] - 0s 167us/step
Loss: 0.5561737691618732
Train member Nr 4/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00049: early stopping
97/97 [==============================] - 0s 177us/step
Loss: 0.4973839023678573
Train member Nr 5/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00234: early stopping
97/97 [==============================] - 0s 178us/step
Loss: 0.7060904075804445
Mean loss: 0.6195999998407266

##################################################################
Search iteration Nr 52/100
##################################################################

Train member Nr 1/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00090: early stopping
97/97 [==============================] - 0s 374us/step
Loss: 0.5847447330189735
Train member Nr 2/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00105: early stopping
97/97 [==============================] - 0s 271us/step
Loss: 0.7413804899785936
Train member Nr 3/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00050: early stopping
97/97 [==============================] - 0s 276us/step
Loss: 0.5414633950621811
Train member Nr 4/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00064: early stopping
97/97 [==============================] - 0s 271us/step
Loss: 0.49918813066384227
Train member Nr 5/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00110: early stopping
97/97 [==============================] - 0s 299us/step
Loss: 0.677074699672227
Mean loss: 0.6087702896791635

##################################################################
Search iteration Nr 53/100
##################################################################

Train member Nr 1/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00086: early stopping
97/97 [==============================] - 0s 317us/step
Loss: 0.5778909233427539
Train member Nr 2/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00057: early stopping
97/97 [==============================] - 0s 260us/step
Loss: 0.7773271971142169
Train member Nr 3/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00078: early stopping
97/97 [==============================] - 0s 278us/step
Loss: 0.5356052305895028
Train member Nr 4/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00043: early stopping
97/97 [==============================] - 0s 263us/step
Loss: 0.5063461618325145
Train member Nr 5/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00075: early stopping
97/97 [==============================] - 0s 298us/step
Loss: 0.8405938805993071
Mean loss: 0.647552678695659

##################################################################
Search iteration Nr 54/100
##################################################################

Train member Nr 1/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00095: early stopping
97/97 [==============================] - 0s 147us/step
Loss: 0.6184471311028471
Train member Nr 2/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00121: early stopping
97/97 [==============================] - 0s 219us/step
Loss: 0.7764065388551692
Train member Nr 3/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00067: early stopping
97/97 [==============================] - 0s 140us/step
Loss: 0.5622247583472851
Train member Nr 4/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00053: early stopping
97/97 [==============================] - 0s 142us/step
Loss: 0.5030448657950175
Train member Nr 5/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00252: early stopping
97/97 [==============================] - 0s 207us/step
Loss: 0.706169266368925
Mean loss: 0.6332585120938488

##################################################################
Search iteration Nr 55/100
##################################################################

Train member Nr 1/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00097: early stopping
97/97 [==============================] - 0s 255us/step
Loss: 0.7265369652472821
Train member Nr 2/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00378: early stopping
97/97 [==============================] - 0s 294us/step
Loss: 1.1189842691126557
Train member Nr 3/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00219: early stopping
97/97 [==============================] - 0s 331us/step
Loss: 0.5730404810807139
Train member Nr 4/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00189: early stopping
97/97 [==============================] - 0s 281us/step
Loss: 0.5276464912080273
Train member Nr 5/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00079: early stopping
97/97 [==============================] - 0s 276us/step
Loss: 0.9729743704353411
Mean loss: 0.7838365154168041

##################################################################
Search iteration Nr 56/100
##################################################################

Train member Nr 1/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00052: early stopping
97/97 [==============================] - 0s 161us/step
Loss: 0.5901366638154099
Train member Nr 2/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00052: early stopping
97/97 [==============================] - 0s 155us/step
Loss: 0.748859883583698
Train member Nr 3/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00051: early stopping
97/97 [==============================] - 0s 126us/step
Loss: 0.5369045931039397
Train member Nr 4/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00052: early stopping
97/97 [==============================] - 0s 125us/step
Loss: 0.48236439830249117
Train member Nr 5/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00150: early stopping
97/97 [==============================] - 0s 130us/step
Loss: 0.7203726983561958
Mean loss: 0.6157276474323469

##################################################################
Search iteration Nr 57/100
##################################################################

Train member Nr 1/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00053: early stopping
97/97 [==============================] - 0s 232us/step
Loss: 0.5919818263692954
Train member Nr 2/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00121: early stopping
97/97 [==============================] - 0s 116us/step
Loss: 0.7325438371638662
Train member Nr 3/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00049: early stopping
97/97 [==============================] - 0s 120us/step
Loss: 0.5553790883919627
Train member Nr 4/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00049: early stopping
97/97 [==============================] - 0s 119us/step
Loss: 0.4989747355893715
Train member Nr 5/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00117: early stopping
97/97 [==============================] - 0s 119us/step
Loss: 0.7222890091925552
Mean loss: 0.6202336993414101

##################################################################
Search iteration Nr 58/100
##################################################################

Train member Nr 1/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00074: early stopping
97/97 [==============================] - 0s 272us/step
Loss: 0.5965557878779382
Train member Nr 2/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00095: early stopping
97/97 [==============================] - 0s 254us/step
Loss: 0.7182407999776074
Train member Nr 3/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00072: early stopping
97/97 [==============================] - 0s 280us/step
Loss: 0.5535035111854986
Train member Nr 4/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00045: early stopping
97/97 [==============================] - 0s 269us/step
Loss: 0.49569724699885576
Train member Nr 5/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00143: early stopping
97/97 [==============================] - 0s 274us/step
Loss: 0.6899256512676317
Mean loss: 0.6107845994615063

##################################################################
Search iteration Nr 59/100
##################################################################

Train member Nr 1/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00096: early stopping
97/97 [==============================] - 0s 282us/step
Loss: 0.7277834820993168
Train member Nr 2/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00337: early stopping
97/97 [==============================] - 0s 282us/step
Loss: 0.8635594082861832
Train member Nr 3/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00503: early stopping
97/97 [==============================] - 0s 308us/step
Loss: 0.5694228444517273
Train member Nr 4/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00092: early stopping
97/97 [==============================] - 0s 295us/step
Loss: 0.5252913648320228
Train member Nr 5/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00276: early stopping
97/97 [==============================] - 0s 275us/step
Loss: 0.8386993147048754
Mean loss: 0.704951282874825

##################################################################
Search iteration Nr 60/100
##################################################################

Train member Nr 1/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00045: early stopping
97/97 [==============================] - 0s 125us/step
Loss: 0.5964011242709208
Train member Nr 2/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00080: early stopping
97/97 [==============================] - 0s 128us/step
Loss: 0.7145459903884179
Train member Nr 3/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00076: early stopping
97/97 [==============================] - 0s 130us/step
Loss: 0.5443257440611259
Train member Nr 4/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00045: early stopping
97/97 [==============================] - 0s 124us/step
Loss: 0.5029294429366121
Train member Nr 5/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00101: early stopping
97/97 [==============================] - 0s 124us/step
Loss: 0.6816831642819434
Mean loss: 0.6079770931878041

##################################################################
Search iteration Nr 61/100
##################################################################

Train member Nr 1/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00087: early stopping
97/97 [==============================] - 0s 145us/step
Loss: 0.5867400568785127
Train member Nr 2/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00075: early stopping
97/97 [==============================] - 0s 140us/step
Loss: 0.7356016721922097
Train member Nr 3/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00062: early stopping
97/97 [==============================] - 0s 134us/step
Loss: 0.5525470016543398
Train member Nr 4/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00053: early stopping
97/97 [==============================] - 0s 136us/step
Loss: 0.4945925978041187
Train member Nr 5/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00140: early stopping
97/97 [==============================] - 0s 141us/step
Loss: 0.7124262820814073
Mean loss: 0.6163815221221176

##################################################################
Search iteration Nr 62/100
##################################################################

Train member Nr 1/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00050: early stopping
97/97 [==============================] - 0s 208us/step
Loss: 0.5961553927549382
Train member Nr 2/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00111: early stopping
97/97 [==============================] - 0s 89us/step
Loss: 0.7478066774987683
Train member Nr 3/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00052: early stopping
97/97 [==============================] - 0s 103us/step
Loss: 0.5482784300735316
Train member Nr 4/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00047: early stopping
97/97 [==============================] - 0s 111us/step
Loss: 0.49546575853505087
Train member Nr 5/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00116: early stopping
97/97 [==============================] - 0s 104us/step
Loss: 0.6770502331945085
Mean loss: 0.6129512984113595

##################################################################
Search iteration Nr 63/100
##################################################################

Train member Nr 1/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00104: early stopping
97/97 [==============================] - 0s 175us/step
Loss: 0.5869781036966855
Train member Nr 2/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00046: early stopping
97/97 [==============================] - 0s 196us/step
Loss: 0.7266165183991501
Train member Nr 3/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00047: early stopping
97/97 [==============================] - 0s 258us/step
Loss: 0.5495972525827664
Train member Nr 4/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00051: early stopping
97/97 [==============================] - 0s 186us/step
Loss: 0.4952440814873607
Train member Nr 5/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00045: early stopping
97/97 [==============================] - 0s 216us/step
Loss: 0.7005290496595127
Mean loss: 0.6117930011650949

##################################################################
Search iteration Nr 64/100
##################################################################

Train member Nr 1/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00178: early stopping
97/97 [==============================] - 0s 219us/step
Loss: 0.5906489092050139
Train member Nr 2/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00065: early stopping
97/97 [==============================] - 0s 242us/step
Loss: 1.119279062625059
Train member Nr 3/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00141: early stopping
97/97 [==============================] - 0s 238us/step
Loss: 0.5814655469250434
Train member Nr 4/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00073: early stopping
97/97 [==============================] - 0s 237us/step
Loss: 0.5126202659508616
Train member Nr 5/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00057: early stopping
97/97 [==============================] - 0s 240us/step
Loss: 0.8473105147941825
Mean loss: 0.7302648599000321

##################################################################
Search iteration Nr 65/100
##################################################################

Train member Nr 1/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00114: early stopping
97/97 [==============================] - 0s 297us/step
Loss: 0.5803450524192495
Train member Nr 2/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00119: early stopping
97/97 [==============================] - 0s 336us/step
Loss: 0.7419576884545002
Train member Nr 3/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00059: early stopping
97/97 [==============================] - 0s 281us/step
Loss: 0.5416696830508635
Train member Nr 4/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00048: early stopping
97/97 [==============================] - 0s 288us/step
Loss: 0.5011700840340447
Train member Nr 5/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00080: early stopping
97/97 [==============================] - 0s 267us/step
Loss: 0.7462078283742531
Mean loss: 0.6222700672665822

##################################################################
Search iteration Nr 66/100
##################################################################

Train member Nr 1/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00185: early stopping
97/97 [==============================] - 0s 221us/step
Loss: 0.5895351153059104
Train member Nr 2/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00172: early stopping
97/97 [==============================] - 0s 208us/step
Loss: 0.7355148706239524
Train member Nr 3/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00064: early stopping
97/97 [==============================] - 0s 208us/step
Loss: 0.5530033268264889
Train member Nr 4/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00064: early stopping
97/97 [==============================] - 0s 199us/step
Loss: 0.4994433288721694
Train member Nr 5/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00191: early stopping
97/97 [==============================] - 0s 206us/step
Loss: 0.7120850224470355
Mean loss: 0.6179163328151114

##################################################################
Search iteration Nr 67/100
##################################################################

Train member Nr 1/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00164: early stopping
97/97 [==============================] - 0s 236us/step
Loss: 0.577682946146149
Train member Nr 2/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00106: early stopping
97/97 [==============================] - 0s 245us/step
Loss: 0.7300031609141949
Train member Nr 3/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00068: early stopping
97/97 [==============================] - 0s 275us/step
Loss: 0.5382803721526235
Train member Nr 4/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00090: early stopping
97/97 [==============================] - 0s 307us/step
Loss: 0.5049552100220907
Train member Nr 5/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00114: early stopping
97/97 [==============================] - 0s 242us/step
Loss: 0.7281012104958603
Mean loss: 0.6158045799461837

##################################################################
Search iteration Nr 68/100
##################################################################

Train member Nr 1/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00141: early stopping
97/97 [==============================] - 0s 201us/step
Loss: 0.5909974575042725
Train member Nr 2/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00059: early stopping
97/97 [==============================] - 0s 214us/step
Loss: 0.8148520828522358
Train member Nr 3/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00148: early stopping
97/97 [==============================] - 0s 207us/step
Loss: 0.539841590775657
Train member Nr 4/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00128: early stopping
97/97 [==============================] - 0s 223us/step
Loss: 0.49459148805166026
Train member Nr 5/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00161: early stopping
97/97 [==============================] - 0s 284us/step
Loss: 0.8255491705284905
Mean loss: 0.6531663579424631

##################################################################
Search iteration Nr 69/100
##################################################################

Train member Nr 1/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00055: early stopping
97/97 [==============================] - 0s 112us/step
Loss: 0.6254548737683248
Train member Nr 2/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00045: early stopping
97/97 [==============================] - 0s 82us/step
Loss: 0.7341433179747198
Train member Nr 3/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00044: early stopping
97/97 [==============================] - 0s 84us/step
Loss: 0.5566485619422087
Train member Nr 4/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00053: early stopping
97/97 [==============================] - 0s 88us/step
Loss: 0.5176946066089512
Train member Nr 5/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00050: early stopping
97/97 [==============================] - 0s 78us/step
Loss: 0.6893453275420002
Mean loss: 0.624657337567241

##################################################################
Search iteration Nr 70/100
##################################################################

Train member Nr 1/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00046: early stopping
97/97 [==============================] - 0s 200us/step
Loss: 0.5962209369718414
Train member Nr 2/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00063: early stopping
97/97 [==============================] - 0s 212us/step
Loss: 0.7440869500956584
Train member Nr 3/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00047: early stopping
97/97 [==============================] - 0s 212us/step
Loss: 0.547088206121602
Train member Nr 4/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00044: early stopping
97/97 [==============================] - 0s 233us/step
Loss: 0.4916588719358149
Train member Nr 5/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00076: early stopping
97/97 [==============================] - 0s 263us/step
Loss: 0.689240754879627
Mean loss: 0.6136591440009088

##################################################################
Search iteration Nr 71/100
##################################################################

Train member Nr 1/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00062: early stopping
97/97 [==============================] - 0s 231us/step
Loss: 0.5833874670500608
Train member Nr 2/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00120: early stopping
97/97 [==============================] - 0s 225us/step
Loss: 0.7078346235235942
Train member Nr 3/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00054: early stopping
97/97 [==============================] - 0s 241us/step
Loss: 0.5351739396754
Train member Nr 4/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00045: early stopping
97/97 [==============================] - 0s 236us/step
Loss: 0.48322979015173373
Train member Nr 5/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00082: early stopping
97/97 [==============================] - 0s 233us/step
Loss: 0.6839676874200094
Mean loss: 0.5987187015641596

##################################################################
Search iteration Nr 72/100
##################################################################

Train member Nr 1/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00150: early stopping
97/97 [==============================] - 0s 83us/step
Loss: 0.5942591262846878
Train member Nr 2/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00161: early stopping
97/97 [==============================] - 0s 79us/step
Loss: 0.7919852745901678
Train member Nr 3/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00077: early stopping
97/97 [==============================] - 0s 83us/step
Loss: 0.5505882169782501
Train member Nr 4/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00046: early stopping
97/97 [==============================] - 0s 90us/step
Loss: 0.5147699848892763
Train member Nr 5/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00061: early stopping
97/97 [==============================] - 0s 88us/step
Loss: 0.857886367237445
Mean loss: 0.6618977939959654

##################################################################
Search iteration Nr 73/100
##################################################################

Train member Nr 1/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00047: early stopping
97/97 [==============================] - 0s 150us/step
Loss: 0.6067280314632297
Train member Nr 2/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00047: early stopping
97/97 [==============================] - 0s 176us/step
Loss: 0.7437838365122215
Train member Nr 3/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00048: early stopping
97/97 [==============================] - 0s 165us/step
Loss: 0.5529254748649204
Train member Nr 4/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00048: early stopping
97/97 [==============================] - 0s 158us/step
Loss: 0.49576130601548657
Train member Nr 5/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00066: early stopping
97/97 [==============================] - 0s 189us/step
Loss: 0.6835012958221829
Mean loss: 0.6165399889356082

##################################################################
Search iteration Nr 74/100
##################################################################

Train member Nr 1/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00154: early stopping
97/97 [==============================] - 0s 234us/step
Loss: 0.5819818451232517
Train member Nr 2/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00142: early stopping
97/97 [==============================] - 0s 182us/step
Loss: 0.8183173365199689
Train member Nr 3/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00072: early stopping
97/97 [==============================] - 0s 175us/step
Loss: 0.5689627242457006
Train member Nr 4/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00119: early stopping
97/97 [==============================] - 0s 197us/step
Loss: 0.5029289028079239
Train member Nr 5/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00167: early stopping
97/97 [==============================] - 0s 207us/step
Loss: 0.8204519146496487
Mean loss: 0.6585285446692988

##################################################################
Search iteration Nr 75/100
##################################################################

Train member Nr 1/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00060: early stopping
97/97 [==============================] - 0s 131us/step
Loss: 0.583038788480857
Train member Nr 2/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00058: early stopping
97/97 [==============================] - 0s 126us/step
Loss: 0.7518381328926873
Train member Nr 3/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00059: early stopping
97/97 [==============================] - 0s 123us/step
Loss: 0.5580489939635562
Train member Nr 4/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00044: early stopping
97/97 [==============================] - 0s 153us/step
Loss: 0.49280328726031114
Train member Nr 5/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00218: early stopping
97/97 [==============================] - 0s 113us/step
Loss: 0.6856648221458357
Mean loss: 0.6142788049486494

##################################################################
Search iteration Nr 76/100
##################################################################

Train member Nr 1/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00050: early stopping
97/97 [==============================] - 0s 237us/step
Loss: 0.6011302059458703
Train member Nr 2/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00049: early stopping
97/97 [==============================] - 0s 233us/step
Loss: 0.7434410505073586
Train member Nr 3/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00045: early stopping
97/97 [==============================] - 0s 219us/step
Loss: 0.552064833874555
Train member Nr 4/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00043: early stopping
97/97 [==============================] - 0s 213us/step
Loss: 0.5036529013791036
Train member Nr 5/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00050: early stopping
97/97 [==============================] - 0s 285us/step
Loss: 0.6874202342377496
Mean loss: 0.6175418451889274

##################################################################
Search iteration Nr 77/100
##################################################################

Train member Nr 1/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00052: early stopping
97/97 [==============================] - 0s 151us/step
Loss: 0.5906239883186891
Train member Nr 2/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00056: early stopping
97/97 [==============================] - 0s 153us/step
Loss: 0.7242318969411948
Train member Nr 3/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00049: early stopping
97/97 [==============================] - 0s 260us/step
Loss: 0.5653322821425408
Train member Nr 4/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00048: early stopping
97/97 [==============================] - 0s 157us/step
Loss: 0.4771663214742523
Train member Nr 5/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00057: early stopping
97/97 [==============================] - 0s 156us/step
Loss: 0.6839375797006273
Mean loss: 0.6082584137154609

##################################################################
Search iteration Nr 78/100
##################################################################

Train member Nr 1/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00110: early stopping
97/97 [==============================] - 0s 337us/step
Loss: 0.6870982567059625
Train member Nr 2/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00066: early stopping
97/97 [==============================] - 0s 277us/step
Loss: 1.1188649209504276
Train member Nr 3/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00118: early stopping
97/97 [==============================] - 0s 292us/step
Loss: 0.5525955997177006
Train member Nr 4/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00069: early stopping
97/97 [==============================] - 0s 317us/step
Loss: 0.5318248548458532
Train member Nr 5/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00320: early stopping
97/97 [==============================] - 0s 296us/step
Loss: 0.9015295032373408
Mean loss: 0.7583826270914569

##################################################################
Search iteration Nr 79/100
##################################################################

Train member Nr 1/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00056: early stopping
97/97 [==============================] - 0s 276us/step
Loss: 0.5938628309780789
Train member Nr 2/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00046: early stopping
97/97 [==============================] - 0s 280us/step
Loss: 0.7481067623059774
Train member Nr 3/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00047: early stopping
97/97 [==============================] - 0s 271us/step
Loss: 0.5457462603898392
Train member Nr 4/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00045: early stopping
97/97 [==============================] - 0s 279us/step
Loss: 0.5018553008738252
Train member Nr 5/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00080: early stopping
97/97 [==============================] - 0s 324us/step
Loss: 0.6897757658638906
Mean loss: 0.6158693840823223

##################################################################
Search iteration Nr 80/100
##################################################################

Train member Nr 1/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00115: early stopping
97/97 [==============================] - 0s 178us/step
Loss: 0.589564318509446
Train member Nr 2/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00082: early stopping
97/97 [==============================] - 0s 185us/step
Loss: 0.7347417479937839
Train member Nr 3/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00062: early stopping
97/97 [==============================] - 0s 180us/step
Loss: 0.5561142551530268
Train member Nr 4/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00046: early stopping
97/97 [==============================] - 0s 180us/step
Loss: 0.49388295473511684
Train member Nr 5/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00154: early stopping
97/97 [==============================] - 0s 255us/step
Loss: 0.6897738557500938
Mean loss: 0.6128154264282935

##################################################################
Search iteration Nr 81/100
##################################################################

Train member Nr 1/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00088: early stopping
97/97 [==============================] - 0s 126us/step
Loss: 0.6093503857396313
Train member Nr 2/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00057: early stopping
97/97 [==============================] - 0s 131us/step
Loss: 0.8216301571462572
Train member Nr 3/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00083: early stopping
97/97 [==============================] - 0s 121us/step
Loss: 0.5640802398784873
Train member Nr 4/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00053: early stopping
97/97 [==============================] - 0s 170us/step
Loss: 0.49628691452065693
Train member Nr 5/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00097: early stopping
97/97 [==============================] - 0s 117us/step
Loss: 0.8314838212789949
Mean loss: 0.6645663037128056

##################################################################
Search iteration Nr 82/100
##################################################################

Train member Nr 1/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00100: early stopping
97/97 [==============================] - 0s 177us/step
Loss: 0.5789944824484206
Train member Nr 2/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00126: early stopping
97/97 [==============================] - 0s 211us/step
Loss: 0.7471384584289236
Train member Nr 3/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00068: early stopping
97/97 [==============================] - 0s 173us/step
Loss: 0.5374974356484168
Train member Nr 4/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00044: early stopping
97/97 [==============================] - 0s 200us/step
Loss: 0.4933106536717759
Train member Nr 5/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00086: early stopping
97/97 [==============================] - 0s 205us/step
Loss: 0.679297875497759
Mean loss: 0.6072477811390591

##################################################################
Search iteration Nr 83/100
##################################################################

Train member Nr 1/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00097: early stopping
97/97 [==============================] - 0s 273us/step
Loss: 0.6560606360435486
Train member Nr 2/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00162: early stopping
97/97 [==============================] - 0s 385us/step
Loss: 0.8250195556080219
Train member Nr 3/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00142: early stopping
97/97 [==============================] - 0s 247us/step
Loss: 0.5433980914735302
Train member Nr 4/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00074: early stopping
97/97 [==============================] - 0s 249us/step
Loss: 0.5018986856814512
Train member Nr 5/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00175: early stopping
97/97 [==============================] - 0s 246us/step
Loss: 0.8181399801342758
Mean loss: 0.6689033897881657

##################################################################
Search iteration Nr 84/100
##################################################################

Train member Nr 1/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00070: early stopping
97/97 [==============================] - 0s 278us/step
Loss: 0.6717564727842193
Train member Nr 2/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00076: early stopping
97/97 [==============================] - 0s 274us/step
Loss: 0.8197638779571376
Train member Nr 3/5
--------------------------------------
Restoring model weights from the end of the best epoch
Epoch 00077: early stopping
97/97 [==============================] - 0s 225us/step
Loss: 0.5413025632961509
Train member Nr 4/5
--------------------------------------
</pre></div></div>
</div>
</div>
<div class="section" id="Make-predictions-on-the-test-data-set">
<h2>Make predictions on the test data set<a class="headerlink" href="#Make-predictions-on-the-test-data-set" title="Permalink to this headline">¶</a></h2>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">xarray</span> <span class="k">as</span> <span class="nn">xr</span>

<span class="c1"># make prediction</span>
<span class="n">pred</span><span class="p">,</span> <span class="n">pred_all_members</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">testX</span><span class="p">)</span>
<span class="n">test_label</span> <span class="o">=</span> <span class="n">scaler_l</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">testy</span><span class="p">)</span>

<span class="c1"># reshape data into an xarray data array that is 3-D</span>
<span class="n">pred_map</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">label</span><span class="p">[</span><span class="n">lead</span><span class="o">+</span><span class="n">shift</span><span class="p">:,:,:][</span><span class="n">test_indeces</span><span class="p">])</span>
<span class="n">pred_map</span><span class="o">.</span><span class="n">values</span> <span class="o">=</span> <span class="n">scaler_l</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">pred</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">testX</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">label</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]))</span>

<span class="n">test_label_map</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">label</span><span class="p">[</span><span class="n">lead</span><span class="o">+</span><span class="n">shift</span><span class="p">:,:,:][</span><span class="n">test_indeces</span><span class="p">])</span>
<span class="n">test_label_map</span><span class="o">.</span><span class="n">values</span> <span class="o">=</span> <span class="n">test_label</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">testX</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">label</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]))</span>

<span class="c1"># calculate the ONI</span>
<span class="n">pred_oni</span> <span class="o">=</span> <span class="n">pred_map</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="nb">dict</span><span class="p">(</span><span class="n">lat</span><span class="o">=</span><span class="nb">slice</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">lon</span><span class="o">=</span><span class="nb">slice</span><span class="p">(</span><span class="mi">190</span><span class="p">,</span> <span class="mi">240</span><span class="p">))]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="s2">&quot;lat&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="s1">&#39;lon&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Plot-prediction-for-the-ONI">
<h2>Plot prediction for the ONI<a class="headerlink" href="#Plot-prediction-for-the-ONI" title="Permalink to this headline">¶</a></h2>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="c1"># Plot ONI Forecasts</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mf">1.8</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">testtimey</span><span class="p">,</span> <span class="n">pred_oni</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;navy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">testtimey</span><span class="p">,</span> <span class="n">oni</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">testtimey</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span> <span class="n">testtimey</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]],</span> <span class="s2">&quot;k&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Time [Year]&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;ONI [K]&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">axhspan</span><span class="p">(</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="o">-</span><span class="mi">6</span><span class="p">,</span> <span class="n">facecolor</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span>  <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axhspan</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="n">facecolor</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span><span class="n">zorder</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="n">testtimey</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">testtimey</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;Lead time: </span><span class="si">{lead}</span><span class="s2"> month&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Evaluate-the-seasonal-skill-for-predicting-the-ONI">
<h2>Evaluate the seasonal skill for predicting the ONI<a class="headerlink" href="#Evaluate-the-seasonal-skill-for-predicting-the-ONI" title="Permalink to this headline">¶</a></h2>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">ninolearn.plot.evaluation</span> <span class="k">import</span> <span class="n">plot_correlation</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="c1"># make a plot of the seasonal correaltion</span>
<span class="c1"># note: - pd.tseries.offsets.MonthBegin(1) appears to ensure that the correlations are plotted</span>
<span class="c1"># agains the correct season</span>

<span class="n">plot_correlation</span><span class="p">(</span><span class="n">oni</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">testtimey</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span> <span class="n">testtimey</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]],</span> <span class="n">pred_oni</span><span class="p">,</span> <span class="n">testtimey</span> <span class="o">-</span> <span class="n">pd</span><span class="o">.</span><span class="n">tseries</span><span class="o">.</span><span class="n">offsets</span><span class="o">.</span><span class="n">MonthBegin</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Check-the-correlations-on-a-map">
<h2>Check the correlations on a map<a class="headerlink" href="#Check-the-correlations-on-a-map" title="Permalink to this headline">¶</a></h2>
<p>In the following the pearson correlation coefficent between the predicted and the observed value for each grid point are computed and afterwards plotted.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># rehshape predictions to a map</span>
<span class="n">corr_map</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">pred</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

<span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">corr_map</span><span class="p">)):</span>
    <span class="n">corr_map</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">corrcoef</span><span class="p">(</span><span class="n">pred</span><span class="p">[:,</span><span class="n">j</span><span class="p">],</span> <span class="n">test_label</span><span class="p">[:,</span><span class="n">j</span><span class="p">])[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span>
<span class="n">corr_map</span> <span class="o">=</span> <span class="n">corr_map</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">label</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]))</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="o">%</span><span class="k">matplotlib</span> inline
<span class="c1"># Plot correlation map</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;Lead time: </span><span class="si">{lead}</span><span class="s2"> month&quot;</span><span class="p">)</span>
<span class="n">C</span><span class="o">=</span><span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">corr_map</span><span class="p">,</span> <span class="n">origin</span><span class="o">=</span><span class="s1">&#39;lower&#39;</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">cb</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">C</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Animate-the-full-test-prediction">
<h2>Animate the full test prediction<a class="headerlink" href="#Animate-the-full-test-prediction" title="Permalink to this headline">¶</a></h2>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">matplotlib.animation</span> <span class="k">as</span> <span class="nn">animation</span>

<span class="k">def</span> <span class="nf">animation_ed</span><span class="p">(</span><span class="n">true</span><span class="p">,</span> <span class="n">pred</span><span class="p">,</span> <span class="n">nino</span><span class="p">,</span>  <span class="n">nino_pred</span><span class="p">,</span> <span class="n">time</span><span class="p">):</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="mi">7</span><span class="p">),</span> <span class="n">squeeze</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="n">vmin</span> <span class="o">=</span> <span class="o">-</span><span class="mi">3</span>
    <span class="n">vmax</span> <span class="o">=</span> <span class="mi">3</span>

    <span class="n">true_im</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">true</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">origin</span><span class="o">=</span><span class="s1">&#39;lower&#39;</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="n">vmin</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">vmax</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">bwr</span><span class="p">)</span>
    <span class="n">pred_im</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">pred</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">origin</span><span class="o">=</span><span class="s1">&#39;lower&#39;</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="n">vmin</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">vmax</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">bwr</span><span class="p">)</span>
    <span class="n">title</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>

    <span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">time</span><span class="p">,</span> <span class="n">nino</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">time</span><span class="p">,</span> <span class="n">nino_pred</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="n">time</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">time</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>

    <span class="n">vline</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">time</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">time</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span> <span class="p">[</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span><span class="mi">10</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>


    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
        <span class="n">true_im</span><span class="o">.</span><span class="n">set_data</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">pred_im</span><span class="o">.</span><span class="n">set_data</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">title_str</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">datetime_as_string</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">time</span><span class="o">.</span><span class="n">values</span><span class="p">)[:</span><span class="mi">10</span><span class="p">]</span>
        <span class="n">title</span><span class="o">.</span><span class="n">set_text</span><span class="p">(</span><span class="n">title_str</span><span class="p">)</span>

        <span class="n">vline</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_data</span><span class="p">([</span><span class="n">data</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">data</span><span class="p">[</span><span class="mi">2</span><span class="p">]],[</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span><span class="mi">10</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">data_gen</span><span class="p">():</span>
        <span class="n">k</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">kmax</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">true</span><span class="p">)</span>
        <span class="k">while</span> <span class="n">k</span><span class="o">&lt;</span><span class="n">kmax</span><span class="p">:</span>

            <span class="k">yield</span> <span class="n">true</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">time</span><span class="p">[</span><span class="n">k</span><span class="p">]],</span> <span class="n">pred</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">time</span><span class="p">[</span><span class="n">k</span><span class="p">]],</span> <span class="n">time</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
            <span class="n">k</span><span class="o">+=</span><span class="mi">1</span>

    <span class="n">ani</span> <span class="o">=</span> <span class="n">animation</span><span class="o">.</span><span class="n">FuncAnimation</span><span class="p">(</span><span class="n">fig</span><span class="p">,</span> <span class="n">update</span><span class="p">,</span> <span class="n">data_gen</span><span class="p">,</span> <span class="n">interval</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">repeat</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">save_count</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">true</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">(</span><span class="s2">&quot;all&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">ani</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">IPython.display</span> <span class="k">import</span> <span class="n">HTML</span>
<span class="n">ani</span> <span class="o">=</span> <span class="n">animation_ed</span><span class="p">(</span><span class="n">test_label_map</span><span class="p">,</span> <span class="n">pred_map</span><span class="p">,</span>
                   <span class="n">oni</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">testtimey</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span><span class="n">testtimey</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]],</span> <span class="n">pred_oni</span><span class="p">,</span>
                   <span class="n">testtimey</span><span class="p">)</span>

<span class="n">HTML</span><span class="p">(</span><span class="n">ani</span><span class="o">.</span><span class="n">to_html5_video</span><span class="p">())</span>
</pre></div>
</div>
</div>
<p>So it looks like that the Encoder-Decoder ensemble has some skill. However, more research is needed to release the full potential of this model.</p>
<p>Maybe you are interested working on this? :D</p>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../forecasts.html" class="btn btn-neutral float-right" title="Some forecasts" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="deep_ensemble.html" class="btn btn-neutral float-left" title="Deep ensemble for ENSO-forecasting" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019, Paul Petersik

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>